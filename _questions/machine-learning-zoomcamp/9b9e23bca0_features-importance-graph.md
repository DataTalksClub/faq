---
course: machine-learning-zoomcamp
id: 9b9e23bca0
question: Features Importance graph
section: 6. Decision Trees and Ensemble Learning
sort_order: 2630
---

I like this visual implementation of features importance in scikit-learn library:

[https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)

It actually adds std.errors to features importance -> so that you can trace stability of features (important for a modelâ€™s explainability) over the different params of the model.

Ivan Brigida

